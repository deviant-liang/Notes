# 雜項

## 網卡到CPU過程
當網卡（Network Interface Card, NIC）接收到網絡上的數據包時，這些數據包會經過以下幾個步驟傳遞到 CPU 並最終交給用戶空間的應用程序：

a. 硬體接收資料
網卡會接收到來自網絡的數據包，並將其存儲在網卡的接收緩衝區（receive buffer）中。
b. 中斷和 DMA (Direct Memory Access)
當網卡準備好資料時，它會向 CPU 發送中斷信號。這會觸發操作系統的中斷處理程序。
在許多現代系統中，網卡和內存之間的資料傳遞通常使用 DMA 技術，這樣資料可以直接寫入主記憶體而無需經過 CPU 的處理，從而提高效率。
c. 中斷處理
CPU 在接收到網卡的中斷信號後，會將資料從網卡的接收緩衝區移動到主記憶體（Kernel 空間）。
網卡傳輸的數據包會被內核的網路子系統（如 netdev）接收並進行初步處理（例如，檢查資料包的有效性、解封裝等）。

## Kernel在socket programming做了什麼
當資料包進入內核後，內核會根據 socket 的協議處理數據包，並將其交給相應的應用程序。具體過程如下：

a. 網路層協議處理
網路層（如 IP 協議）會根據數據包的目的地（例如 IP 位址）決定該如何處理數據包。如果數據包是針對本機的，則會繼續處理。
例如，當收到 IP 資料包後，內核會根據目的端口和協議（TCP/UDP）將資料包交給相應的套接字（socket）。
b. Socket 處理
每個進程都會有一個或多個套接字（socket）來進行網路通信。內核會根據資料包的 目的端口號 和 協議（如 TCP 或 UDP）來找到與之對應的套接字。
當套接字被找到後，內核會將該數據包交給套接字的接收緩衝區，等待進程從中讀取。
c. 進程與套接字的對應
當應用程式通過 recv() 或 read() 等系統調用從套接字讀取資料時，內核會將資料從套接字的緩衝區讀取並傳遞給應用程序。
3. 如何決定將資料傳給哪顆核心（CPU 核心）
內核負責管理 CPU 資源，並決定將資料傳遞給哪個核心，這涉及到 多核處理 和 負載均衡 的問題。具體來說，內核會使用以下機制來決定在哪個 CPU 核心處理這些資料：

a. 中斷負載均衡
當網卡接收到中斷信號時，操作系統會根據 CPU 的負載情況來選擇一個核心來處理這個中斷。這稱為 中斷親和性（interrupt affinity），它會將中斷分配給一個特定的 CPU 核心或一組核心，以避免核心之間的頻繁切換，提高性能。

在一些系統中，操作系統會根據網卡的 NIC 中斷，將處理該網卡資料的工作負載綁定到特定的核心，以減少上下文切換和 cache 缺失，這有助於提高效率。

b. 多核心和多執行緒
當數據包被處理並交給應用程式時，操作系統可能會將處理這些資料的工作負載分配給不同的核心。例如，內核可能會根據進程的親和性或調度策略，將某些處理操作分配給不同的核心。
如果應用程序是多線程的，則不同的線程可能會在不同的 CPU 核心上運行，根據內核的 進程調度器 來決定具體哪個核心執行。
c. CPU 親和性（CPU Affinity）
操作系統內核會根據 CPU 親和性，也就是將某些進程或中斷固定到特定的 CPU 核心上，以提高性能。這意味著某些 CPU 核心負責處理來自特定設備（如網卡）的中斷和數據，這有助於減少資源競爭和增加處理效率。

## PCIe
PCIe（Peripheral Component Interconnect Express，外圍元件互連快車）是一種高速的電腦總線標準，用於連接主板與各種外部設備（如顯示卡、網路卡、儲存設備等）。它是目前使用最廣泛的擴展介面標準，取代了較舊的 PCI 和 AGP 標準。

## MAC
即便每個設備都有一個唯一的 MAC 位址，我們仍然需要 IP 位址，主要是因為 MAC 位址和 IP 位址在網路中的作用不同，它們分別解決了不同層級的通信問題。

1. 作用層級不同
MAC 位址屬於 資料鏈路層（OSI 模型的第 2 層），主要用於局域網（LAN）中設備之間的通信。它幫助設備在同一個局域網內進行識別和直接通信。
IP 位址屬於 網路層（OSI 模型的第 3 層），用於在不同網路之間進行通信，並幫助設備定位並路由資料包到目標網路。
2. 局域網與廣域網的通信需求
MAC 位址只能在局部網路內進行識別，它並不適合用於跨越不同網絡或網段的通信。例如，兩個位於不同地理位置的設備，雖然它們的 MAC 位址是唯一的，但它們無法直接通過 MAC 位址進行跨網絡通信。
IP 位址則是用來定位設備所在的「網路」，從而使其能夠在廣域網（WAN）或互聯網上進行通信。IP 位址幫助數據包找到正確的路由，並跨越不同的網路到達目標設備。
3. IP 位址的可變性
MAC 位址是固定的，它是硬體層級的標識碼，通常由設備製造商指定，並且不會改變。
IP 位址是動態的，設備可以根據其所在的網路環境獲取不同的 IP 位址（如 DHCP 或靜態配置）。當設備移動到不同的網路環境時，IP 位址會發生變化，而 MAC 位址保持不變。
4. MAC 位址與 IP 位址的結合使用
ARP（地址解析協議）：當一台設備需要將數據發送給另一台設備時，網絡設備使用 IP 位址 來尋找目標設備，並通過 ARP 協議將 IP 位址 解析為 MAC 位址。在同一個局域網內，IP 位址會對應到每台設備的 MAC 位址。這樣，當資料包進入資料鏈路層時，它就能夠找到目標設備的 MAC 位址來進行實際的數據傳輸。

IP 位址 是路由和網路層的核心，將資料包從源設備傳送到目標設備，即使它們位於不同的網路。MAC 位址則用來在同一網路（局域網內）確定具體的設備。

5. 範圍和路由
MAC 位址：僅在 同一個局域網內有效，它無法跨越路由器或其他網路設備進行通信。
IP 位址：可以跨越不同的網路範圍，實現 跨越多個路由器和交換機的廣域網通信。它的作用是幫助網絡中各設備進行全球範圍的定位和路由。
6. 範例說明
假設你在家庭中有一個路由器，它連接到互聯網。當你使用電腦或手機訪問網站時：

電腦的 IP 位址 用於確定該設備在整個網際網路中的位置。網站伺服器根據你的 IP 位址回應你的請求。
當數據包在你的家庭網路內部進行傳遞時，它使用 MAC 位址 在本地網路中找到發送和接收設備。你的電腦會使用 ARP 協議來解析目標設備的 MAC 位址，然後將數據包發送到路由器或目標設備。
總結
MAC 位址 用於同一局域網內設備的唯一標識，它無法跨網路範圍傳遞，因此無法實現跨網路通信。
IP 位址 用於跨越不同網絡進行通信，並在路由過程中幫助數據包找到目的地。因此，兩者的作用並不重疊，而是互補的：MAC 位址處理本地設備識別和通信，IP 位址則處理跨網絡的路由和定位。

## False sharing
False sharing 是一種會影響多執行緒（或多處理器）程式性能的現象，特別是在使用共享記憶體的多執行緒環境下發生。它是由多個執行緒或處理器「誤」共享同一個快取行（cache line）中的不同變數而引起的，即使這些變數之間其實是互不相關的。

Cache line 的概念
在現代處理器中，記憶體是以「快取行」（cache line）為單位讀取的。典型的快取行大小可能是 64 bytes，也就是說，處理器每次從記憶體中讀取一個快取行時，它會一次性讀取一整個快取行中的資料，這個快取行可能包含多個變數。當執行緒對快取行中的資料進行讀寫操作時，整個快取行會被加載到處理器的快取（L1、L2、L3 等），以加快存取速度。

False Sharing 是如何發生的？
False sharing 發生在多個執行緒或多個處理器同時操作同一個快取行中的不同變數時。即使這些變數是彼此獨立的，處理器仍然會將它們所在的整個快取行標記為「共享」，而當一個執行緒或處理器更新這個快取行中的某個變數時，其他執行緒或處理器的快取行會被標記為「無效」（invalidate），導致它們必須重新從記憶體中加載最新的快取行。這樣反覆的快取失效和重載過程會帶來不必要的性能損失。

False Sharing 的過程舉例
假設有兩個執行緒（Thread A 和 Thread B）：

Thread A 和 Thread B 各自操作不同的變數 x 和 y，但 x 和 y 正好落在同一個快取行中（假設一個快取行為 64 bytes）。
Thread A 更新變數 x，導致其所在的快取行被標記為「已修改」。
隨後，Thread B 需要讀取或更新變數 y，但由於這兩個變數共享同一個快取行，Thread B 的快取行被標記為「無效」，這意味著它必須重新從記憶體中取得整個快取行的最新副本，即便它只想操作 y。
當 Thread B 更新 y 時，這個快取行再度被修改，進而導致 Thread A 的快取行也變為無效，然後 Thread A 需要再次重新加載這個快取行。
這樣反覆的快取同步和失效，儘管兩個執行緒操作的是不同的變數，仍會導致系統的快取一致性機制（cache coherence protocol，如 MESI 協議）頻繁觸發，這就是所謂的 False Sharing。

## NUMA
隨著 CPU 性能的不斷提高，UMA 架構阻礙了伺服器性能的進一步提升，所以又提出了 NUMA 架構，把記憶體控制器集成在 CPU 內部，由 CPU 來直接管理和訪問記憶體。Intel 從 Nehalem (2007年) 處理器開始把記憶體控制器集成在 CPU 內部，這樣記憶體就從 CPU 的匯流排來訪問了，性能大大提高；但是記憶體從集中管理變成了由各個 CPU 來分別管理。CPU 對於自己所控制的本地記憶體可以直接訪問，存取速度是最快的；對於連接在其他 CPU 上的異地記憶體則需要通過 CPU 之間的 Ultra Path Interconnect Link 匯流排 (這種匯流排以前也叫 QPI – Quick Path Interconnect) 來間接訪問，存取速度有所降低。

NUMA 架構下的 False Sharing
在 NUMA 系統中，false sharing 的影響會更加嚴重，因為處理器之間的快取一致性通信會涉及多個「NUMA 節點」（NUMA node）間的數據同步。

NUMA 節點之間的延遲： 當某個執行緒修改了它所在的 NUMA 節點的快取行中的一部分資料時，如果另一個 NUMA 節點中的執行緒正在操作同一個快取行的其他資料，那麼就會觸發快取一致性協議。這意味著該快取行必須在 NUMA 節點之間同步，並可能導致遠端記憶體的存取（因為另一個 NUMA 節點必須獲取該快取行的最新副本）。這種跨 NUMA 節點的快取同步延遲比在單一處理器內部要大得多，從而加劇了性能問題。

## rdtsc rdtscp差別
TSC是一個64位的暫存器，幾乎在所有x86平台上均會提供。它存放的是CPU從啟動以來執行的指令周期數，通過rdtsc指令可以將TSC的數值存放在EDX:EDA中。
隨著CPU往多核心、多處理器的方向上走，使用TSC會遇到一些問題：
- CPU可能會根據情況動態調節工作頻率，那單位時間CPU指令週期樹就會發生變化。CPU進入休眠再次重啟後，TSC會清零。
- 同一處理器的多個核心，rdtsc的結果會同步嗎(近代機器應該是同步嗎？)
- 處理器後來引入亂序執行的功能，導致程序讀取的TSC結果可能不準。

新版本CPU中引入常量項的TSC(const rate TSC)。可以通過cat /proc/cpuinfo | grep const_tsc查看是否支持。如果支持代表都是同步的，如果沒有，且是Intel的CPU，不同處理器的不同核心之間不同步。

## Pipeline
- Structure Hazard:
不同的 instruction 同時想要去用同一個資源
解決方法：每個 intruction 要在相同的 stage 用特定的 resource
例子：add 在第四個 stage 就已經算完可以準備 write back 了，但因為要避免 structure hazard，需要在第五個 stage 才能 write back

- Data Hazard
Data Hazard and Forwarding (R-Type and R-Type)
three types: (instruction i1 followed by instruction i2)
RAW(read after write): i2 tries to read operand before i1 write it

- Control Hazard (Branch Hazard)

## Write實際上是怎麼做的
內部狀態依賴：由於 printf 涉及內部的緩衝區管理，它必須對緩衝區進行操作，而這需要使用內部的狀態變數。如果在處理輸出時有信號發生，並且信號處理程序也調用了 printf 或相關的標準 I/O 函數，可能會導致這些緩衝區和狀態變數處於不一致的狀態，從而產生競爭條件和數據損壞。

鎖機制：為了保護 printf 的內部緩衝區和狀態變數，標準 I/O 函數庫通常會使用一些同步機制，如鎖（locks）。這意味著 printf 不是一個簡單的、單一的系統調用，而是涉及到更複雜的邏輯。當信號發生時，如果信號處理程序調用了 printf，可能會打斷這些同步操作，導致死鎖（deadlock）或不一致的行為。

write直接將資料送入kernel，交由kernel管理